<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Publications | Kaushal Kumar Maurya</title>
    <meta name="author" content="Kaushal Kumar Maurya">
    <meta name="description" content="">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://kaushal0494.github.io/Publications/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Kaushal </span>Kumar Maurya</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item active">
                <a class="nav-link" href="/Publications/">Publications<span class="sr-only">(current)</span></a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/Achievements/">Achievements</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/Miscellaneous/">Miscellaneous</a>
              </li>

              <!-- Resume -->
              <li class="nav-item ">
                <a class="nav-link" href="/assets/pdf/Kaushal_Resume.pdf" target="_blank">Resume</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Publications</h1>
            <p class="post-description"></p>
          </header>

          <article>
            <!-- _pages/publications.md -->
<div class="publications">
  <h2 class="year">2023</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/trie_nlg.png"><abbr class="badge"><span>Auto-Completion</span></abbr><abbr class="badge"><span>Trie QAC</span></abbr><abbr class="badge"><span>NLG Augmentation</span></abbr>
</div>

        <!-- Entry bib key -->
        <div id="maurya2023utilizing" class="col-sm-8">
        <!-- Title -->
        <div class="title">Trie-NLG: Trie Context Augmentation to Improve Personalized Query Auto-Completion for Short and Unseen Prefixes</div>
        <!-- Author -->
        <div class="author">
        

        <a href="https://kaushal0494.github.io/">Kaushal Kumar Maurya</a>, Maunendra Sankar Desarkar, Manish Gupta, and
          <span class="more-authors" title="click to view 1 more author" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '1 more author' ? 'Puneet Agrawal' : '1 more author';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">1 more author</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In ECML-PKDD 2023 (Journal Track: DAMI)</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/maurya2023_pkdd.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
            <a href="https://github.com/kaushal0494/Trie-NLG" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          <a href="https://www.youtube.com/watch?v=MuKzQzJGxE4" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Talk</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-altmetric-id="" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
            <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Query auto-completion (QAC) aims at suggesting plausible completions for a given query prefix. Traditionally, QAC systems have leveraged tries curated from historical query logs to suggest most popular completions. In this context, there are two specific scenarios that are difficult to handle for any QAC system: short prefixes (which are inherently ambiguous) and unseen prefixes. Recently, personalized Natural Language Generation (NLG) models have been proposed to leverage previous session queries as context for addressing these two challenges. However, such NLG models suffer from two drawbacks: (1) some of the previous session queries could be noisy and irrelevant to the user intent for the current prefix, and (2) NLG models cannot directly incorporate historical query popularity. This motivates us to propose a novel NLG model for QAC, Trie-NLG, which jointly leverages popularity signals from trie and personalization signals from previous session queries. We train the Trie-NLG model by augmenting the prefix with rich context comprising of recent session queries and top trie completions. This simple modeling approach overcomes the limitations of trie-based and NLG-based approaches, and leads to state-of-the-art performance. We evaluate the Trie-NLG model using two large QAC datasets. On average, our model achieves huge 57% and 14% boost in MRR over the popular trie-based lookup and the strong BART-based baseline methods, respectively.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">maurya2023utilizing</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Trie-NLG: Trie Context Augmentation to Improve Personalized Query Auto-Completion for Short and Unseen Prefixes}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Maurya, Kaushal Kumar and Desarkar, Maunendra Sankar and Gupta, Manish and Agrawal, Puneet}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ECML-PKDD 2023 (Journal Track: DAMI)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">talk</span> <span class="p">=</span> <span class="s">{https://www.youtube.com/watch?v=MuKzQzJGxE4}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/lrmt.png"><abbr class="badge"><span>Extremely LRLs</span></abbr><abbr class="badge"><span>Neural MT</span></abbr><abbr class="badge"><span>Lexical Similarity</span></abbr>
</div>

        <!-- Entry bib key -->
        <div id="maurya2023utilizinh" class="col-sm-8">
        <!-- Title -->
        <div class="title">Utilizing Lexical Similarity to Enable Zero-Shot Machine Translation for Extremely Low-resource Languages</div>
        <!-- Author -->
        <div class="author">
        

        <a href="https://kaushal0494.github.io/">Kaushal Kumar Maurya</a>, Rahul Kejriwal, Maunendra Sankar Desarkar, and
          <span class="more-authors" title="click to view 1 more author" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '1 more author' ? 'Anoop Kunchukuttan' : '1 more author';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">1 more author</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In arXiv preprint arXiv:2305.05214</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2305.05214" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/pdf/2305.05214.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-altmetric-id="" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
            <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We address the task of machine translation from an extremely low-resource language (LRL) to English using cross-lingual transfer from a closely related high-resource language (HRL). For many of these languages, no parallel corpora are available, even monolingual corpora are limited and representations in pre-trained sequence-to-sequence models are absent. These factors limit the benefits of cross-lingual transfer from shared embedding spaces in multilingual models. However, many extremely LRLs have a high level of lexical similarity with related HRLs. We utilize this property by injecting character and character-span noise into the training data of the HRL prior to learning the vocabulary. This serves as a regularizer which makes the model more robust to lexical divergences between the HRL and LRL and better facilitates cross-lingual transfer. On closely related HRL and LRL pairs from multiple language families, we observe that our method significantly outperforms the baseline MT as well as approaches proposed previously to address cross-lingual transfer between closely related languages. We also show that the proposed character-span noise injection performs better than the unigram-character noise injection.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">maurya2023utilizinh</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Utilizing Lexical Similarity to Enable Zero-Shot Machine Translation for Extremely Low-resource Languages}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Maurya, Kaushal Kumar and Kejriwal, Rahul and Desarkar, Maunendra Sankar and Kunchukuttan, Anoop}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2305.05214}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/divhsk.png"><abbr class="badge"><span>NLG</span></abbr><abbr class="badge"><span>Diverse Headlines</span></abbr><abbr class="badge"><span>Self-attention</span></abbr>
</div>

        <!-- Entry bib key -->
        <div id="maurya-desarkar-2023-divhsk" class="col-sm-8">
        <!-- Title -->
        <div class="title">DIVHSK: Diverse Headline Generation using Self-Attention based Keyword Selection</div>
        <!-- Author -->
        <div class="author">
        

        Venkatesh E, <a href="https://kaushal0494.github.io/">Kaushal Kumar Maurya</a>, Deepak Kumar, and
          <span class="more-authors" title="click to view 1 more author" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '1 more author' ? 'Maunendra Sankar Desarkar' : '1 more author';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">1 more author</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Findings of the Association for Computational Linguistics: ACL 2023</em>, Jul 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://aclanthology.org/2023.findings-acl.118.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/kaushal0494/DivHSK" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-altmetric-id="" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
            <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Diverse headline generation is an NLP task where given a news article, the goal is to generate multiple headlines that are true to the content of the article, but are different among themselves. This task aims to exhibit and exploit semantically similar one-to-many relationships between a source news article and multiple target headlines. Towards this, we propose a novel model called DivHSK. It has two components: KeySelect for selecting the important keywords, and SeqGen, for finally generating the multiple diverse headlines. In KeySelect, we cluster the self-attention heads of the last layer of the pre-trained encoder and select the most-attentive theme and general keywords from the source article. Then, cluster-specific keyword sets guide the SeqGen, a pre-trained encoder-decoder model, to generate diverse yet semantically similar headlines. The proposed model consistently outperformed existing literature and our strong baselines and emerged as a state-of-the-art model. Additionally, We have also created a high-quality multi-reference headline dataset from news articles.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">maurya-desarkar-2023-divhsk</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{DIVHSK: Diverse Headline Generation using Self-Attention based Keyword Selection}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{E, Venkatesh and Maurya, Kaushal Kumar and Kumar, Deepak and Desarkar, Maunendra Sankar}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Findings of the Association for Computational Linguistics: ACL 2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Toronto, Canada}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/metaxng.png"><abbr class="badge"><span>Cross-Lingual</span></abbr><abbr class="badge"><span>Meta-Learning</span></abbr><abbr class="badge"><span>Typology</span></abbr>
</div>

        <!-- Entry bib key -->
        <div id="maurya-desarkar-2022-meta" class="col-sm-8">
        <!-- Title -->
        <div class="title">Meta-X_NLG: A Meta-Learning Approach Based on Language Clustering for Zero-Shot Cross-Lingual Transfer and Generation</div>
        <!-- Author -->
        <div class="author">
        

        <a href="https://kaushal0494.github.io/">Kaushal Kumar Maurya</a>, and Maunendra Desarkar</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Findings of the Association for Computational Linguistics: ACL 2022</em>, May 2022
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://aclanthology.org/2022.findings-acl.24.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/kaushal0494/Meta_XNLG" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          <a href="https://aclanthology.org/2022.findings-acl.24.mp4" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Talk</a>
            <a href="/assets/pdf/metaxng_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-doi="10.18653/v1/2022.findings-acl.24" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
            <span class="__dimensions_badge_embed__" data-doi="10.18653/v1/2022.findings-acl.24" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Recently, the NLP community has witnessed a rapid advancement in multilingual and cross-lingual transfer research where the supervision is transferred from high-resource languages (HRLs) to low-resource languages (LRLs). However, the cross-lingual transfer is not uniform across languages, particularly in the zero-shot setting. Towards this goal, one promising research direction is to learn shareable structures across multiple tasks with limited annotated data. The downstream multilingual applications may benefit from such a learning setup as most of the languages across the globe are low-resource and share some structures with other languages. In this paper, we propose a novel meta-learning framework (called Meta-X_NLG) to learn shareable structures from typologically diverse languages based on meta-learning and language clustering. This is a step towards uniform cross-lingual transfer for unseen languages. We first cluster the languages based on language representations and identify the centroid language of each cluster. Then, a meta-learning algorithm is trained with all centroid languages and evaluated on the other languages in the zero-shot setting. We demonstrate the effectiveness of this modeling on two NLG tasks (Abstractive Text Summarization and Question Generation), 5 popular datasets and 30 typologically diverse languages. Consistent improvements over strong baselines demonstrate the efficacy of the proposed framework. The careful design of the model makes this end-to-end NLG setup less vulnerable to the accidental translation problem, which is a prominent concern in zero-shot cross-lingual NLG tasks.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">maurya-desarkar-2022-meta</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Meta-X$_{NLG}$: A Meta-Learning Approach Based on Language Clustering for Zero-Shot Cross-Lingual Transfer and Generation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Maurya, Kaushal Kumar and Desarkar, Maunendra}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Findings of the Association for Computational Linguistics: ACL 2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Dublin, Ireland}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2022.findings-acl.24}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/2022.findings-acl.24}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{269--284}</span><span class="p">,</span>
  <span class="na">talk</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2022.findings-acl.24.mp4}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/codemix.png"><abbr class="badge"><span>Hostility</span></abbr><abbr class="badge"><span>Code-mix NLP</span></abbr>
</div>

        <!-- Entry bib key -->
        <div id="10.1145/3501247.3531579" class="col-sm-8">
        <!-- Title -->
        <div class="title">Hostility Detection in Online Hindi-English Code-Mixed Conversations</div>
        <!-- Author -->
        <div class="author">
        

        Aditi Bagora, Kamal Shrestha, <a href="https://kaushal0494.github.io/">Kaushal Kumar Maurya</a>, and
          <span class="more-authors" title="click to view 1 more author" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '1 more author' ? 'Maunendra Sankar Desarkar' : '1 more author';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">1 more author</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In 14th ACM Web Science Conference 2022</em>, May 2022
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://dl.acm.org/doi/pdf/10.1145/3501247.3531579" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/AditiBagora/Hasoc2021CodeMix" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          <a href="https://dl.acm.org/doi/10.1145/3501247.3531579" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Talk</a>
            <a href="/assets/pdf/websci.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-doi="10.1145/3501247.3531579" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
            <span class="__dimensions_badge_embed__" data-doi="10.1145/3501247.3531579" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>With the rise in accessibility and popularity of various social media platforms, people have started expressing and communicating their ideas, opinions, and interests online. While these platforms are active sources of entertainment and idea-sharing, they also attract hostile and offensive content equally. Identification of hostile posts is an essential and challenging task. In particular, Hindi-English Code-Mixed online posts of conversational nature (which have a hierarchy of posts, comments, and replies) have escalated the challenges. There are two major challenges: (1) the complex structure of Code-Mixed text and (2) filtering the relevant previous context for a given utterance. To overcome these challenges, in this paper, we propose a novel hierarchical neural network architecture to identify hostile posts/comments/replies in online Hindi-English Code-Mixed conversations. We leverage large multilingual pre-trained (mLPT) models like mBERT, XLMR, and MuRIL. The mLPT models provide a rich representation of code-mix text and hierarchical modeling leads to a natural abstraction and selection of the relevant context. The propose model consistently outperformed all the baselines and emerged as a state-of-the-art performing model. We conducted multiple analyses and ablation studies to prove the robustness of the proposed model.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3501247.3531579</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bagora, Aditi and Shrestha, Kamal and Maurya, Kaushal Kumar and Desarkar, Maunendra Sankar}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hostility Detection in Online Hindi-English Code-Mixed Conversations}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781450391917}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3501247.3531579}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3501247.3531579}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{14th ACM Web Science Conference 2022}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{390–400}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Neural networks, hostility detection, Code-Mixed data}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Barcelona, Spain}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{WebSci '22}</span><span class="p">,</span>
  <span class="na">talk</span> <span class="p">=</span> <span class="s">{https://dl.acm.org/doi/10.1145/3501247.3531579}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/zmbart.png"><abbr class="badge"><span>Cross-Lingual</span></abbr><abbr class="badge"><span>Unsupervised</span></abbr><abbr class="badge"><span>Transfer-Learning</span></abbr>
</div>

        <!-- Entry bib key -->
        <div id="maurya-etal-2021-zmbart" class="col-sm-8">
        <!-- Title -->
        <div class="title">ZmBART: An Unsupervised Cross-lingual Transfer Framework for Language Generation</div>
        <!-- Author -->
        <div class="author">
        

        <a href="https://kaushal0494.github.io/">Kaushal Kumar Maurya</a>, Maunendra Sankar Desarkar, Yoshinobu Kano, and
          <span class="more-authors" title="click to view 1 more author" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '1 more author' ? 'Kumari Deepshikha' : '1 more author';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">1 more author</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</em>, Aug 2021
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://aclanthology.org/2021.findings-acl.248.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/kaushal0494/ZmBART" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          <a href="https://aclanthology.org/2021.findings-acl.248.mp4" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Talk</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-doi="10.18653/v1/2021.findings-acl.248" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
            <span class="__dimensions_badge_embed__" data-doi="10.18653/v1/2021.findings-acl.248" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Despite the recent advancement in NLP research, cross-lingual transfer for natural language generation is relatively understudied. In this work, we transfer supervision from
high resource language (HRL) to multiple lowresource languages (LRLs) for natural language generation (NLG). We consider four
NLG tasks (text summarization, question generation, news headline generation, and distractor generation) and three syntactically diverse languages, i.e., English, Hindi, and
Japanese. We propose an unsupervised crosslingual language generation framework (called
ZmBART) that does not use any parallel
or pseudo-parallel/back-translated data. In
this framework, we further pre-train mBART
sequence-to-sequence denoising auto-encoder
model with an auxiliary task using monolingual data of three languages. The objective
function of the auxiliary task is close to the
target tasks which enriches the multi-lingual
latent representation of mBART and provides
good initialization for target tasks. Then, this
model is fine-tuned with task-specific supervised English data and directly evaluated with
low-resource languages in the Zero-shot setting. To overcome catastrophic forgetting
and spurious correlation issues, we applied
freezing model component and data arguclosely related languages. We also show that the proposed character-span noise injection performs better than the unigram-character noise injection.mentation approaches respectively. This simple
modeling approach gave us promising results.
We experimented with few-shot training (with
1000 supervised data-points) which boosted
the model performance further. We performed
several ablations and cross-lingual transferability analysis to demonstrate the robustness of
ZmBART.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">maurya-etal-2021-zmbart</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Z}m{BART}: An Unsupervised Cross-lingual Transfer Framework for Language Generation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Maurya, Kaushal Kumar and Desarkar, Maunendra Sankar and Kano, Yoshinobu and Deepshikha, Kumari}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Online}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2021.findings-acl.248}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/2021.findings-acl.248}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2804--2818}</span><span class="p">,</span>
  <span class="na">talk</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2021.findings-acl.248.mp4}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/host.png"><abbr class="badge"><span>Hostility</span></abbr><abbr class="badge"><span>Multilingual</span></abbr>
</div>

        <!-- Entry bib key -->
        <div id="DBLP:journals/corr/abs-2101-04998" class="col-sm-8">
        <!-- Title -->
        <div class="title">Coarse and Fine-Grained Hostility Detection in Hindi Posts using Fine
               Tuned Multilingual Embeddings</div>
        <!-- Author -->
        <div class="author">
        

        Arkadipta De, Venkatesh Elangovan, <a href="https://kaushal0494.github.io/">Kaushal Kumar Maurya</a>, and
          <span class="more-authors" title="click to view 1 more author" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '1 more author' ? 'Maunendra Sankar Desarkar' : '1 more author';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">1 more author</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>CoRR</em>, Aug 2021
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2101.04998" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://www.springerprofessional.de/en/coarse-and-fine-grained-hostility-detection-in-hindi-posts-using/19047892" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/Arko98/Hostility-Detection-in-Hindi-Constraint-2021" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-altmetric-id="" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
            <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Due to the wide adoption of social media platforms like Facebook, Twitter, etc., there is an emerging need of detecting online posts that can go against the community acceptance standards. The hostility detection task has been well explored for resource-rich languages like English, but is unexplored for resource-constrained languages like Hindi due to the unavailability of large suitable data. We view this hostility detection as a multi-label multi-class classification problem. We propose an effective neural network-based technique for hostility detection in Hindi posts. We leverage pre-trained multilingual Bidirectional Encoder Representations of Transformer (mBERT) to obtain the contextual representations of Hindi posts. We have performed extensive experiments including different pre-processing techniques, pre-trained models, neural architectures, hybrid strategies, etc. Our best performing neural classifier model includes One-vs-the-Rest approach where we obtained 92.60%, 81.14%, 69.59%, 75.29% and 73.01% F1 scores for hostile, fake, hate, offensive, and defamation labels respectively. The proposed model (https://github.com/Arko98/Hostility-Detection-in-Hindi-Constraint-2021) outperformed the existing baseline models and emerged as the state-of-the-art model for detecting hostility in the Hindi posts.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">DBLP:journals/corr/abs-2101-04998</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{De, Arkadipta and Elangovan, Venkatesh and Maurya, Kaushal Kumar and Desarkar, Maunendra Sankar}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Coarse and Fine-Grained Hostility Detection in Hindi Posts using Fine
                 Tuned Multilingual Embeddings}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{CoRR}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{abs/2101.04998}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">eprinttype</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2101.04998}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Tue, 17 Aug 2021 16:23:03 +0200}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/journals/corr/abs-2101-04998.bib}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/imed.png"><abbr class="badge"><span>Token-Classification</span></abbr><abbr class="badge"><span>Math Document</span></abbr>
</div>

        <!-- Entry bib key -->
        <div id="DBLP:journals/es/MadisettyMAD21" class="col-sm-8">
        <!-- Title -->
        <div class="title">A neural approach for detecting inline mathematical expressions from
               scientific documents</div>
        <!-- Author -->
        <div class="author">
        

        Sreekanth Madisetty, <a href="https://kaushal0494.github.io/">Kaushal Kumar Maurya</a>, Akiko Aizawa, and
          <span class="more-authors" title="click to view 1 more author" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '1 more author' ? 'Maunendra Sankar Desarkar' : '1 more author';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">1 more author</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Expert Syst. J. Knowl. Eng.</em>, Aug 2021
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.12576" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-doi="10.1111/exsy.12576" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
            <span class="__dimensions_badge_embed__" data-doi="10.1111/exsy.12576" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Scientific documents generally contain multiple mathematical expressions in them. Detecting inline mathematical expressions are one of the most important and challenging tasks in scientific text mining. Recent works that detect inline mathematical expressions in scientific documents have looked at the problem from an image processing perspective. There is little work that has targeted the problem from NLP perspective. Towards this, we define a few features and applied Conditional Random Fields (CRF) to detect inline mathematical expressions in scientific documents. Apart from this feature based approach, we also propose a hybrid algorithm that combines Bidirectional Long Short Term Memory networks (Bi-LSTM) and feature-based approach for this task. Experimental results suggest that this proposed hybrid method outperforms several baselines in the literature and also individual methods in the hybrid approach.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">DBLP:journals/es/MadisettyMAD21</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Madisetty, Sreekanth and Maurya, Kaushal Kumar and Aizawa, Akiko and Desarkar, Maunendra Sankar}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A neural approach for detecting inline mathematical expressions from
                 scientific documents}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Expert Syst. J. Knowl. Eng.}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{38}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1111/exsy.12576}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1111/exsy.12576}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Tue, 13 Jul 2021 13:25:01 +0200}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/journals/es/MadisettyMAD21.bib}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/disgen.png"><abbr class="badge"><span>Q&amp;A, MCQ</span></abbr><abbr class="badge"><span>Multi-Decoder</span></abbr><abbr class="badge"><span>LSTM</span></abbr>
</div>

        <!-- Entry bib key -->
        <div id="10.1145/3340531.3411997" class="col-sm-8">
        <!-- Title -->
        <div class="title">Learning to Distract: A Hierarchical Multi-Decoder Network for Automated Generation of Long Distractors for Multiple-Choice Questions for Reading Comprehension</div>
        <!-- Author -->
        <div class="author">
        

        <a href="https://kaushal0494.github.io/">Kaushal Kumar Maurya</a>, and Maunendra Sankar Desarkar</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</em>, Aug 2020
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://dl.acm.org/doi/pdf/10.1145/3340531.3411997" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/kaushal0494/HMD_Network" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-doi="10.1145/3340531.3411997" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
            <span class="__dimensions_badge_embed__" data-doi="10.1145/3340531.3411997" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The task of generating incorrect options for multiple-choice questions is termed as distractor generation problem. The task requires high cognitive skills and is extremely challenging to automate. Existing neural approaches for the task leverage encoder-decoder architecture to generate long distractors. However, in this process two critical points are ignored - firstly, many methods use Jaccard similarity over a pool of candidate distractors to sample the distractors. This often makes the generated distractors too obvious or not relevant to the question context. Secondly, some approaches did not consider the answer in the model, which caused the generated distractors to be either answer-revealing or semantically equivalent to the answer.In this paper, we propose a novel Hierarchical Multi-Decoder Network (HMD-Net) consisting of one encoder and three decoders, where each decoder generates a single distractor. To overcome the first problem mentioned above, we include multiple decoders with a dis-similarity loss in the loss function. To address the second problem, we exploit richer interaction between the article, question, and answer with a SoftSel operation and a Gated Mechanism. This enables the generation of distractors that are in context with questions but semantically not equivalent to the answers. The proposed model outperformed all the previous approaches significantly in both automatic and manual evaluations. In addition, we also consider linguistic features and BERT contextual embedding with our base model which further push the model performance.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3340531.3411997</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Maurya, Kaushal Kumar and Desarkar, Maunendra Sankar}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781450368599}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3340531.3411997}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3340531.3411997}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 29th ACM International Conference on Information &amp;amp; Knowledge Management}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1115–1124}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{distractor generation, natural language generation, question-answering}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Virtual Event, Ireland}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{CIKM '20}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/mte.png"><abbr class="badge"><span>MT Evaluation</span></abbr><abbr class="badge"><span>Correlation study</span></abbr>
</div>

        <!-- Entry bib key -->
        <div id="maurya2020machine" class="col-sm-8">
        <!-- Title -->
        <div class="title">Machine translation evaluation: Manual versus automatic—a comparative study</div>
        <!-- Author -->
        <div class="author">
        

        <a href="https://kaushal0494.github.io/">Kaushal Kumar Maurya</a>, Renjith P Ravindran, Ch Ram Anirudh, and
          <span class="more-authors" title="click to view 1 more author" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '1 more author' ? 'Kavi Narayana Murthy' : '1 more author';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">1 more author</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Data Engineering and Communication Technology: Proceedings of 3rd ICDECT-2K19</em>, Aug 2020
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://www.researchgate.net/profile/Kaushal-Maurya/publication/338467760_Machine_Translation_Evaluation_Manual_Versus_Automatic-A_Comparative_Study/links/5f4d1177458515a88b9a4ac8/Machine-Translation-Evaluation-Manual-Versus-Automatic-A-Comparative-Study.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="/assets/pdf/mte.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-altmetric-id="" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
            <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The quality of machine translation (MT) is best judged by humans well
versed in both source and target languages. However, automatic techniques are often
used as these are much faster, cheaper and language independent. The goal of this
paper is to check for correlation between manual and automatic evaluation, specifically in the context of Indian languages. To the extent automatic evaluation methods
correlate with the manual evaluations, we can get the best of both worlds. In this
paper, we perform a comparative study of automatic evaluation metrics—BLEU,
NIST, METEOR, TER and WER, against the manual evaluation metric (adequacy),
for English-Hindi translation. We also attempt to estimate the manual evaluation
score of a given MT output from its automatic evaluation score. The data for the study
was sourced from the Workshop on Statistical Machine Translation WMT14.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">maurya2020machine</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Machine translation evaluation: Manual versus automatic—a comparative study}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Maurya, Kaushal Kumar and Ravindran, Renjith P and Anirudh, Ch Ram and Murthy, Kavi Narayana}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Data Engineering and Communication Technology: Proceedings of 3rd ICDECT-2K19}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{541--553}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>


</div>

          </article>

        </div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Kaushal Kumar Maurya. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll. </a> Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages. </a>Last updated: October 17, 2023.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
